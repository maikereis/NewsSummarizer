{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from news_summarizer.webdriver import WebDriverFactory, ShutilBrowserLocator\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class BaseCrawler(ABC):\n",
    "    @abstractmethod\n",
    "    def extract(self, link: str, **kwargs) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class BaseSeleniumCrawler(BaseCrawler, ABC):\n",
    "    def __init__(self, scroll_limit: int = 5) -> None:\n",
    "        self.driver = WebDriverFactory(ShutilBrowserLocator()).get_webdriver()\n",
    "        self.scroll_limit = scroll_limit\n",
    "        self.soup = None\n",
    "\n",
    "\n",
    "class G1Crawler(BaseSeleniumCrawler):\n",
    "    def __init__(self, scroll_limit: int = 5) -> None:\n",
    "        super().__init__(scroll_limit=scroll_limit)\n",
    "        self.links = None\n",
    "\n",
    "    def scroll_page(self) -> None:\n",
    "        load_mode = 0\n",
    "        page_number = 0\n",
    "        last_page_number = 0\n",
    "\n",
    "        while True:\n",
    "            self.driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "            )\n",
    "            time.sleep(np.random.randint(2, 5))\n",
    "            # Wait for the \"Veja mais\" link to appear with the next page number\n",
    "            try:\n",
    "\n",
    "                load_more_link = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.load-more a\"))\n",
    "                )\n",
    "\n",
    "                url = load_more_link.get_dom_attribute(\"href\")\n",
    "                page_number = self._extract_page_number(url)\n",
    "\n",
    "                if page_number > last_page_number:\n",
    "                    load_mode += 1\n",
    "                    last_page_number = page_number\n",
    "\n",
    "                    if load_mode >= 6:\n",
    "                        break\n",
    "                load_more_link.click()\n",
    "            except Exception as e:\n",
    "                print(\"see more link not found yet, scrolling more...\")\n",
    "\n",
    "    def _extract_page_number(self, url):\n",
    "        match = re.search(r\"pagina-(\\d+)\", url)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    def extract(self, link: str, **kwargs) -> None:\n",
    "        self.driver.get(link)\n",
    "        time.sleep(5)\n",
    "        self.scroll_page()\n",
    "        self.soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        self.links = self.soup.find_all(\n",
    "            \"a\", href=True\n",
    "        )  # self.soup.find_all('a', href=True)\n",
    "\n",
    "        self.driver.close()\n",
    "\n",
    "\n",
    "class BandCrawler(BaseSeleniumCrawler):\n",
    "    def __init__(self, scroll_limit: int = 5) -> None:\n",
    "        super().__init__(scroll_limit=scroll_limit)\n",
    "        self.links = None\n",
    "\n",
    "    def scroll_page(self) -> None:\n",
    "        load_more_count = 0\n",
    "\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "\n",
    "            self.driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "            )\n",
    "            time.sleep(np.random.randint(2, 5))\n",
    "\n",
    "            try:\n",
    "                load_more_link = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable(\n",
    "                        (By.CSS_SELECTOR, \"div.jeg_block_loadmore a\")\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                load_more_link.click()\n",
    "\n",
    "                # get the current document Height\n",
    "                new_height = self.driver.execute_script(\n",
    "                    \"return document.body.scrollHeight\"\n",
    "                )\n",
    "\n",
    "                if new_height > last_height:\n",
    "                    load_more_count += 1\n",
    "                    last_height = new_height\n",
    "                    if load_more_count >= 6:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(\"Veja mais link not found yet, scrolling more...\")\n",
    "\n",
    "    def _extract_page_number(self, url):\n",
    "        match = re.search(r\"pagina-(\\d+)\", url)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    def extract(self, link: str, **kwargs) -> None:\n",
    "        self.driver.get(link)\n",
    "        time.sleep(5)\n",
    "        self.scroll_page()\n",
    "        self.soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        self.links = self.soup.find_all(\n",
    "            \"a\", href=True\n",
    "        )\n",
    "\n",
    "class R7Crawler(BaseSeleniumCrawler):\n",
    "    def __init__(self, scroll_limit: int = 5) -> None:\n",
    "        super().__init__(scroll_limit=scroll_limit)\n",
    "        self.links = None\n",
    "\n",
    "    def scroll_page(self) -> None:\n",
    "        \"\"\"Scroll through the LinkedIn page based on the scroll limit.\"\"\"\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        current_scroll = 0\n",
    "        while True:\n",
    "            self.driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "            )\n",
    "            time.sleep(5)\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height or (\n",
    "                self.scroll_limit and current_scroll >= self.scroll_limit\n",
    "            ):\n",
    "                break\n",
    "            last_height = new_height\n",
    "            current_scroll += 1\n",
    "\n",
    "    def extract(self, link: str, **kwargs) -> None:\n",
    "        self.driver.get(link)\n",
    "        time.sleep(5)\n",
    "        self.scroll_page()\n",
    "        self.soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        self.links = self.soup.find_all(\n",
    "            \"a\", href=True\n",
    "        )  # self.soup.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see more link not found yet, scrolling more...\n"
     ]
    }
   ],
   "source": [
    "g1_crawler = G1Crawler()\n",
    "g1_crawler.extract(link='https://g1.globo.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"feed-post-link gui-color-primary gui-color-hover\" cmp-ltrk=\"Home - Materia\" cmp-ltrk-idx=\"1455\" data-mrf-link=\"https://g1.globo.com/politica/noticia/2024/11/27/quem-sao-os-militares-que-resistiram-a-tentativa-de-golpe-e-como-frustraram-o-plano-segundo-a-pf.ghtml\" href=\"https://g1.globo.com/politica/noticia/2024/11/27/quem-sao-os-militares-que-resistiram-a-tentativa-de-golpe-e-como-frustraram-o-plano-segundo-a-pf.ghtml\" mrfobservableid=\"c66f4220-315c-418f-8789-b705624fc88b\"><p elementtiming=\"text-csr\">Quem são os militares que resistiram à tentativa de golpe, segundo a PF</p></a>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_crawler.soup.find_all('a')[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Proposta que pode acabar com aborto legal no Brasil avança na Câmara',\n",
       " 'link': 'https://g1.globo.com/politica/noticia/2024/11/27/ccj-da-camara-aprova-pec-que-pode-acabar-com-aborto-legal-no-brasil.ghtml'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'text': g1_crawler.links[20].text, 'link': g1_crawler.links[20].get('href')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veja mais link not found yet, scrolling more...\n",
      "Veja mais link not found yet, scrolling more...\n"
     ]
    }
   ],
   "source": [
    "band_crawler = BandCrawler()\n",
    "band_crawler.extract(link='https://bandnewstv.uol.com.br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7_crawler = R7Crawler()\n",
    "r7_crawler.extract(link='https://www.r7.com')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_summarizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
